---
title: "All_Studies_Temporal_Normalization"
output: html_document
date: "2023-10-19"
editor_options: 
  chunk_output_type: console
---

The purpose of this script is to read in the studies from the final meta data list and to normalize daily stream concentrations by time. 

Script Workflow:

Step 1) Load in all the individual studies from "meta_final" located within inputs in the repository.  

Step 2) run script that fills in concentrations for missing days in between discrete sampling days and then takes an average by month. 

Step 3) calculate our pseudo yield metric: mg-DOC/L*km^2*yr


Step 4) Calculate the effect size for each watershed: ln[R] = Xburn/Xunburn


# Status: in progress

# ==============================================================================
# Author: Jake Cavaiani 
# 18 October 2023
# ==============================================================================

## Read in libraries 
```{r Jake/Mac Load Packages and}
#for Jake/mac

rm(list=ls(all=T)) #this clears your Environment


library(tidyverse)
library(here)
library(forecastML)
library(zoo)
library(hrbrthemes)
library(viridis)
library(ggpmisc)
library(RobustLinearReg)



```

### Load in meta data ###
```{r load in publications}
studies_file_list <- list.files(path = "inputs/Studies/meta_final/", 
                                  recursive=F, 
                                  pattern=".csv", 
                                  full.names=TRUE)

storm_list_beta<-do.call("list", lapply(studies_file_list, 
                                        read.csv, 
                                        stringsAsFactors=FALSE, 
                                        header=T))

meta_df <-do.call("rbind", lapply(studies_file_list, 
                                     read.csv, 
                                     check.names = FALSE,
                                     stringsAsFactors=FALSE, 
                                     header=T, blank.lines.skip = TRUE, fill=TRUE)) 

```


```{r format date and units}
options(max.print = 40)
# Filtering by only the control vs.impact studies to make sure we have no paper that is included that is any other study design. 

# Crandall is filtered out because the burned and reference sites are not paired so I do that is a separate script and will read that csv in later to merge to this dataframe to get the more accurate effect size calculations 

# The studies that monitor streams more than 5 years following a wildfire are also excluded for this initial code and will be added in later.  

control_impact <- meta_df %>% 
  filter(Design_Control_Burn_Pre_Post == "Control_Reference_vs_Impact",
         Study_ID != "Crandall et al. 2021",
         Mean_Median_or_IndividualSample == "Individual",
         as.numeric(Time_Since_Fire) < 6)

# separate out the time columns 
time_format <- control_impact %>% 
  select(Study_ID, Sampling_Date) 

# Make them all the same format and then merge back together in one column
time_format <- time_format %>% 
  mutate(DateTime = mdy(Sampling_Date),
         DateTime2 = mdy_hm(Sampling_Date), 
         DateTime2 = as.Date(DateTime2)) %>% 
  select(-Sampling_Date) %>% 
  mutate(Sampling_Date = coalesce(DateTime, DateTime2),
         Sampling_Date = as.character(Sampling_Date)) %>% 
  select(-DateTime, -DateTime2) 

# merge this dataframe with the metadata df to make sure all the dates are the same format and there aren't any NAs
control_impact <- control_impact %>% 
  mutate(Sampling_Date = time_format$Sampling_Date)


# changing the structure of the concentrations
control_impact <- control_impact %>% 
  mutate(DOC = as.numeric(DOC),
         NO3 = as.numeric(NO3), 
         Sampling_Date = ymd(Sampling_Date))

# Changing the units to make sure everything is consistent in mg_N_L or mg_C_L
control_impact_units <- control_impact %>% 
  mutate(Area_watershed_km = case_when(Area_unit == 'ha' ~ Area_watershed * .01,
                                       Area_unit == 'km' ~ print(Area_watershed)),
         
         DOC_mg_C_L = case_when(DOC_unit == 'mg_C_L' ~ print(DOC),
                                DOC_unit == 'mg_L' ~ print(DOC),
                                DOC_unit == 'um' ~ DOC * 0.01201),
         
         NO3_mg_N_L = case_when(NO3_unit == 'um' ~ NO3 * 0.014007000,
                                NO3_unit == 'umol_L' ~ NO3 * 0.014007000,
                                NO3_unit == 'umol_NO2_NO3_L' ~ NO3 * 0.014007000,
                                NO3_unit == 'mg_N_L' ~ print(NO3),
                                NO3_unit == 'ug_N_L' ~ NO3 * .001, 
                                NO3_unit == 'mg_L' ~ NO3 * 0.225904780),
         
         DOC_uM_C = case_when(DOC_unit == 'um' ~ print(DOC),
                              DOC_unit == 'mg_C_L' ~ DOC * 83.2639467,
                              DOC_unit == 'mg_L' ~ DOC * 83.2639467),

         NO3_uM_N = case_when(NO3_unit == 'um' ~ print(NO3),
                              NO3_unit == 'umol_L' ~ print(NO3),
                              NO3_unit == 'umol_NO2_NO3_L' ~ print(NO3),
                              NO3_unit == 'mg_L' ~ NO3 * 16.127729,
                              NO3_unit == 'mg_N_L' ~ NO3 * 3.64145101,
                              NO3_unit == 'ug_N_L' ~ NO3 * 0.22594948))

# Creating a site characteristics data frame that I will use to merge later to add in the proper data 
site_data <- control_impact_units %>% 
  select(Study_ID, Pair, latitude, longitude, Area_watershed_km, Climate, Burn_Unburn)

site_data_unique <- site_data %>% 
  group_by(Study_ID, Pair, Area_watershed_km) %>% 
  distinct(Area_watershed_km, .keep_all = TRUE)

```

### Gap filling ###
```{r - gap fill}
# filling in daily time series and interpolating by study and site
control_impact_fill <-  control_impact_units %>% 
  select("Study_ID", "latitude", "longitude", "Area_watershed_km", "Pair", "Climate", "Site", "Burn_Unburn", "Sampling_Date", "DOC_mg_C_L", "NO3_mg_N_L") %>%
  group_by(Study_ID, Site) %>%
  complete(Sampling_Date = seq(min(Sampling_Date), max(Sampling_Date), by = "1 day")) %>% 
  fill(Study_ID:Burn_Unburn) %>%
  fill(Study_ID, Site) %>%
  ungroup() %>%
  group_by(Site) %>%
  mutate(NO3_Interp = na.approx(NO3_mg_N_L, na.rm = FALSE),
         DOC_Interp = na.approx(DOC_mg_C_L, na.rm = FALSE)) %>%
  fill(Study_ID:Burn_Unburn)


control_impact_fill <- control_impact_fill %>% 
  mutate(year = year(Sampling_Date),
         month = month(Sampling_Date),
         day = day(Sampling_Date))
  

```


```{r calculating the temporal normalized data}
# pivoting to make the responses in one column
metadata_long <- control_impact_fill %>%
  pivot_longer(
    cols = NO3_Interp:DOC_Interp,
    names_to = "response_var",
    values_to = "concentration",
    values_drop_na = TRUE
  )


# aggregate by year 
yearly_mean_site <-  metadata_long %>%
  group_by(Study_ID, response_var, Pair, year) %>% 
  summarize(meanConc = mean(concentration)) %>% 
  left_join(site_data) %>% 
  group_by(year) %>% 
  distinct(meanConc, .keep_all = TRUE) %>% 
  mutate(TempNorm = meanConc / Area_watershed_km) 

yearly_mean_site$TempNorm <- format(yearly_mean_site$TempNorm, scientific = F)


```



```{r - plotting functions}
# Plotting #
vn = expression(paste(""*N*O[3]^"-"))
# um = expression(paste(""*N*O[3]^"-"))

give.n <- function(x){
  return(c(y = median(x)*1.5, label = length(x))) 
  # experiment with the multiplier to find the perfect position
}

```

#### EFFECT SIZE 
```{r - Effect size calculation}
# Taking out Hauer and Spencer and Hickenbottom because they have mutliple controls and that is different than the rest of these sites
yearly_mean_site_test <- yearly_mean_site %>%
  filter(Study_ID != "Hauer & Spencer 1998", Study_ID != "Hickenbottom et al. 2023") %>%
  mutate(TempNorm = as.numeric(TempNorm))  

yearly_mean_site_test_2 <- yearly_mean_site_test %>%
  group_by(Study_ID, Pair, year, Burn_Unburn, response_var, Climate) %>%
  dplyr::summarize(Xe = sum(TempNorm[Burn_Unburn == "Burn"], na.rm = TRUE),
                   Xc = sum(TempNorm[Burn_Unburn == "Unburn"], na.rm = TRUE)) # Creating a control and treatment column for the temporal normalization 

yearly_mean_site_test_3 <- yearly_mean_site_test_2 %>%
  select(-Pair) %>%
  group_by(Study_ID, response_var, Climate, year) %>%
  summarize(Xe1 = sum(Xe[Pair == "Site_1"], na.rm = TRUE),
            Xe2 = sum(Xe[Pair == "Site_2"], na.rm = TRUE),
            Xe3 = sum(Xe[Pair == "Site_3"], na.rm = TRUE),
            Xe4 = sum(Xe[Pair == "Site_4"], na.rm = TRUE),
            Xe5 = sum(Xe[Pair == "Site_5"], na.rm = TRUE),
            Xc = sum(Xc[Pair == "Control"], na.rm = TRUE)) # Creating an individual column for each site and merging them into one row. 


# Calculating effect size: ln((MeanBurn/MeanUnburn)) for all the sites with only one control 
yearly_effect_size <- yearly_mean_site_test_3 %>% 
  group_by(Study_ID, response_var, Climate, year) %>%
  mutate(lnR1 = log(Xe1/Xc),
         lnR2 = log(Xe2/Xc),
         lnR3 = log(Xe3/Xc),
         lnR4 = log(Xe4/Xc),
         lnR5 = log(Xe5/Xc))

# This is doing the same thing as chunck before where we are creating a column header for each individual site but doing it for the studies that have multiple controls. 
yearly_mean_hauer_hickenbottom <- yearly_mean_site %>%
  filter(Study_ID == "Hauer & Spencer 1998" | Study_ID == "Hickenbottom et al. 2023") %>%
  mutate(TempNorm = as.numeric(TempNorm))



hauer_hickenbottom_test <- yearly_mean_hauer_hickenbottom %>%
  group_by(Study_ID, Pair, year, Burn_Unburn, response_var, Climate) %>%
  dplyr::summarize(Xe = sum(TempNorm[Burn_Unburn == "Burn"], na.rm = TRUE),
                   Xc = sum(TempNorm[Burn_Unburn == "Unburn"], na.rm = TRUE)) # Creating a control and treatment column for the temporal normalization 

yearly_multiple_control <- hauer_hickenbottom_test %>% 
  group_by(Study_ID, response_var, Climate, year) %>%
  summarize(Xe1 = sum(Xe[Pair == "Site_1"], na.rm = TRUE),
            Xe2 = sum(Xe[Pair == "Site_2"], na.rm = TRUE),
            Xe3 = sum(Xe[Pair == "Site_3"], na.rm = TRUE),
            Xe4 = sum(Xe[Pair == "Site_4"], na.rm = TRUE),
            Xe5 = sum(Xe[Pair == "Site_5"], na.rm = TRUE),
            Xc345 = sum(Xc[Pair == "Control_3_4_5"], na.rm = TRUE),
            Xc2 = sum(Xc[Pair == "Control_2"], na.rm = TRUE),
            Xc = sum(Xc[Pair == "Control_1"], na.rm = TRUE)) 


yearly_effect_multiple <- yearly_multiple_control %>% 
  group_by(Study_ID, response_var, Climate, year) %>%
  mutate(lnR1 = log(Xe1/Xc),
         lnR2 = log(Xe2/Xc2),
         lnR3 = log(Xe3/Xc345),
         lnR4 = log(Xe4/Xc345),
         lnR5 = log(Xe5/Xc345)) %>% 
  ungroup()

# Adding columns to match brie_test_stats
yearly_effect_size <-yearly_effect_size %>% 
  add_column(Xc345 = NA,
             Xc2 = NA) %>% 
  ungroup()

# combining Hauer and Hickenbottom back into the mix 
yearly_effect_size_combine <- yearly_effect_size %>% 
  add_row(yearly_effect_multiple)

# Adding in more broad climate 
unique(yearly_effect_size_combine$Climate)

yearly_effect_size_combine <- yearly_effect_size_combine %>% 
  mutate(yearly_effect_size_combine, Biome = ifelse(grepl("Dfb|Dfc|Dsb", Climate), "Cold",
                              ifelse(grepl("Cfb|Csa|Csb|Cfa", Climate), "Temperate",
                              ifelse(grepl("BSk", Climate), "Arid",
                              ifelse(grepl("As|Af|Am", Climate), "Tropical",
                              ifelse(grepl("ET|EF", Climate), "Polar", "Other"))))))

# pivoting to make the responses in one column
# effect size 
yearly_effect_size_combine_long <- yearly_effect_size_combine %>% 
  pivot_longer(
    cols = lnR1:lnR5,
    names_to = "Effect_size_pair",
    values_to = "Effect_size",
    values_drop_na = TRUE
  ) %>% 
  filter(is.finite(Effect_size))
```

# Add in corrected Crandall and papers that are greater than 5 years to this list 
```{r - combining in studies that were formatted differently so they needed their own script}
# combine the yearly_effect_size_combine_long with Crandall, Abbott, and Rhea. 

Crandall_effect_size <- read_csv(here("Output_for_analysis", "01_Crandall_effect_size", "Crandall_effect_size.csv")) 

abbott_effect_size <- read_csv(here("Output_for_analysis", "02_Abbott_effect_size", "Abbott_effect_size.csv")) 

rhea_effect_size <- read_csv(here("Output_for_analysis", "03_Rhea_effect_size", "Rhea_effect_size.csv")) 


# Adding columns to yearly_effect_size_combine_long to match Crandall_effect_size and above_five_effect_size 
yearly_effect_size_combine_long <-yearly_effect_size_combine_long %>% 
  add_column(Xc34 = NA) %>% 
  ungroup() %>% 
  select(Study_ID, response_var, Climate, year, Xe1, Xe2, Xe3, Xe4, Xe5, Xc, Xc2, Xc34, Xc345, Biome, Effect_size_pair, Effect_size)

# Adding columns to Crandall_effect_size to match yearly_effect_size_combine_long and above_five_effect_size 
Crandall_effect_size <-Crandall_effect_size %>% 
  add_column(Time_Since_Fire = as.numeric(0),
             Biome = "Temperate",
             Xe5 = NA,
             Xc345 = NA) %>% 
  ungroup() %>% 
  select(Study_ID, response_var, Climate, year, Xe1, Xe2, Xe3, Xe4, Xe5, Xc, Xc2, Xc34, Xc345, Biome, Effect_size_pair, Effect_size) 

# Adding columns to abbott_effect_size to match yearly_effect_size_combine_long and Crandall_effect_size 
abbott_effect_size <-abbott_effect_size %>% 
  add_column(Xe2 = NA, 
             Xe3 = NA, 
             Xe4 = NA, 
             Xe5 = NA, 
             Xc2 = NA, 
             Xc34 = NA,
             Xc345 = NA, 
             Biome = NA) %>% 
  ungroup() %>% 
  select(Study_ID, response_var, Climate, year, Xe1, Xe2, Xe3, Xe4, Xe5, Xc, Xc2, Xc34, Xc345, Biome, Effect_size_pair, Effect_size) 

# Adding columns to rhea_effect_size to match abbott_effect_size, yearly_effect_size_combine_long and Crandall_effect_size 
rhea_effect_size <-rhea_effect_size %>% 
  add_column(Xe4 = NA, 
             Xe5 = NA, 
             Xc2 = NA, 
             Xc34 = NA,
             Xc345 = NA, 
             Biome = NA) %>% 
  ungroup() %>% 
  select(Study_ID, response_var, Climate, year, Xe1, Xe2, Xe3, Xe4, Xe5, Xc, Xc2, Xc34, Xc345, Biome, Effect_size_pair, Effect_size) 


# combining all of them back into the mix back into the mix 
yearly_effect_size_combine_long <- yearly_effect_size_combine_long %>% 
  add_row(Crandall_effect_size) %>% 
  add_row(abbott_effect_size) %>% 
  add_row(rhea_effect_size)


### LOOKS LIKE THE TIME SINCE FIRE AND YEARS ARENT PAIRING UP LIKE I WANT THEM TO ####
# Creating a year column with a dataframe that has TSF accurately 
TSF_year <- control_impact %>% 
  mutate(year = year(Sampling_Date)) %>% 
  select(Study_ID, Time_Since_Fire, year) %>% 
  distinct()

# Joining the TSF and the yearly effect size combine long dataframe 
yearly_effect_size_combine_long <- left_join(yearly_effect_size_combine_long, TSF_year, by = c("Study_ID", "year")) %>% 
  distinct(Effect_size, .keep_all = TRUE) 

yearly_effect_size_combine_long$Time_Since_Fire <- as.character(yearly_effect_size_combine_long$Time_Since_Fire) # making time since fire a character 

# Filling in the missing Time Since Fire values because they were originally excluded in the above code 
yearly_effect_size_combine_long <- yearly_effect_size_combine_long %>% 
  mutate(Time_Since_Fire = case_when(Study_ID == 'Abbott et al. 2021' & year == "2017" ~ ">10",
                                     Study_ID == 'Abbott et al. 2021' & year == "2018" ~ ">10",
                                     Study_ID == 'Hauer & Spencer 1998' & year == "1992" ~ "4",
                                     Study_ID == 'Rhea et al. 2021' ~ ">10",
                                     Study_ID == 'Crandall et al. 2021' ~ "0",
                                  TRUE ~ Time_Since_Fire))

yearly_effect_size_combine_long <- yearly_effect_size_combine_long %>% 
  mutate(Biome = case_when(Study_ID == 'Abbott et al. 2021' ~ "Cold",
                           Study_ID == 'Rhea et al. 2021' ~ "Cold",
                         TRUE ~ Biome))

```

```{r - clean up effect size if there are any mistakes csv}

manual_effect_size <- yearly_effect_size_combine_long 



manual_effect_size <- manual_effect_size %>% 
  mutate(Time_Since_Fire = case_when(Study_ID == 'Mast & Clow, 2008' & 
                                     year == '2003' ~ "0",
                                     TRUE ~ Time_Since_Fire))

manual_effect_size <- manual_effect_size %>% 
  mutate(Time_Since_Fire = case_when(Study_ID == 'Murphy et al. 2018' & 
                                     year == '2011' ~ "1",
                                     TRUE ~ Time_Since_Fire))


yearly_effect_size_combine_long <- manual_effect_size


write_csv(yearly_effect_size_combine_long, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "Effect_Size.csv"))



```


# Calculating a confidence interval for all of the effect sizes
```{r}
yearly_effect_size_combine_long_climate <- yearly_effect_size_combine_long %>% 
  filter(Study_ID != "Abbott et al. 2021",
         Study_ID != "Rhea et al. 2021")

# calculating the mean percent_difference by climate
climate_summary_effect <- yearly_effect_size_combine_long_climate %>%
  group_by(response_var, Climate) %>%
  summarise(mean_effect = mean(Effect_size, na.rm = TRUE),
            sd_effect = sd(Effect_size, na.rm = TRUE),
            n_effect = n(),
            Effect_size = mean(Effect_size, na.rm = TRUE)) %>%
  mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect)

# Calculating a confidence interval for all of the effect sizes
# calculating the mean effect_size by climate
TSF_summary_effect <- yearly_effect_size_combine_long %>%
  group_by(Time_Since_Fire, response_var) %>%
  summarise(mean_effect = mean(Effect_size, na.rm = TRUE),
            sd_effect = sd(Effect_size, na.rm = TRUE),
            n_effect = n(),
            Effect_size = mean(Effect_size, na.rm = TRUE)) %>%
  mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect)

write_csv(climate_summary_effect, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "Climate_ES_CIs.csv"))

write_csv(TSF_summary_effect, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "TSF_ES_CIs.csv"))

```



# Plotting
```{r - plotting effect size}
# Ploting #
vn = expression(paste(""*N*O[3]^"-"))

# within 5 years #
under_ten <- yearly_effect_size_combine_long_climate %>% 
  filter(!Time_Since_Fire == ">10") 

write_csv(under_ten, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "Climate_ES_Fig_data.csv"))

# Count how many watersheds are being included for the climate analysis #
under_ten_long <- under_ten %>% 
  pivot_longer(
    cols = Xe1:Xc345,
    names_to = "Watershed",
    values_to = "Mean",
    values_drop_na = TRUE
  ) %>% 
  filter(is.finite(Effect_size))

under_ten_long <- under_ten_long %>% 
  group_by(Study_ID) %>% 
  distinct(Watershed, .keep_all = T) %>% 
  filter(Mean != 0) %>% 
  dplyr::select(Study_ID, Watershed, Mean) 
  

count_climate <- under_ten_long %>% 
  count(Study_ID)
sum(count_climate$n) 
# 53 watersheds are included in the climate analysis 

# geom_jitter for climate for studies within 5 years # 

#
ggplot(under_ten, aes(Effect_size, Climate, color = response_var),
       position = position_dodge(width = -0.5)) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.4, size = 3) +
  geom_pointrange(aes(xmin = lower_ci_effect, xmax = upper_ci_effect,
                      color = response_var),
                  position = position_dodge(width = -0.5), size = 1.5, data = climate_summary_effect) +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "red") +
  xlim(-6.5, 8.5) +
  ylab("Koppen (Climate Classification)") +
  xlab("Effect Size") +
  geom_segment(aes(x = 6.25, xend = 6.25, y = 8.5, yend = 5.5), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 8.5, yend = 8.5), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 5.5, yend = 5.5), color = "black") +
  
  geom_segment(aes(x = 6.25, xend = 6.25, y = 5.3, yend = 1.5), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 5.3, yend = 5.3), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 1.5, yend = 1.5), color = "black") +
  
  geom_segment(aes(x = 6.25, xend = 6.25, y = 1.3, yend = 0.7), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 1.3, yend = 1.3), color = "black") +
  geom_segment(aes(x = 5.5, xend = 6.25, y = 0.7, yend = 0.7), color = "black") +
  annotate("text",
           x = c(7.75, 7.75, 7),
           y = c(7, 3.5, 1),
           label = c("Continental", "Temperate", "Arid"),
           family = "", fontface = "bold") +
  scale_color_manual(values = c("#00AFBB", "#E7B800"),
                     guide = guide_legend(title = "Analyte"),
                     labels = c('DOC', vn)) +
  stat_summary(fun.data = give.n, geom = "text", fun.y = median,
                  position = position_nudge(x = 3.5)) +
  scale_y_discrete(labels=c("Dsb" = "Mediterranean", 
                            "Dfc" = "Subarctic",
                            "Dfb" = "Warm-humid",
                            "Csb" = "Warm-Mediterranean",
                            "Csa" = "Hot-Mediterranean",
                            "Cfb" = "Subtropical highland",
                            "Cfa" = "Humid subtropical",
                            "BSk" = "Cold semi-arid")) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 30),
        axis.text.y = element_text(size = 15),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.17, 0.80))
  

ggsave("Effect_Size.climate.pdf",
       path = here("initial_plots", "04_Meta_merge_all_studies_effect_size"),
       width = 10, height = 8, units = "in")



# geom_jitter for TSF # 
# Reordering for plotting purposes
yearly_effect_size_combine_long$Time_Since_Fire <- factor(yearly_effect_size_combine_long$Time_Since_Fire, levels = c("0", "1", "2", "3", "4", "5", ">10"))

write_csv(yearly_effect_size_combine_long, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "TSF_ES_Fig_data.csv"))

# Count how many watersheds are being included for the climate analysis #
TSF_long <- yearly_effect_size_combine_long %>% 
  pivot_longer(
    cols = Xe1:Xc345,
    names_to = "Watershed",
    values_to = "Mean",
    values_drop_na = TRUE
  ) %>% 
  filter(is.finite(Effect_size))

TSF_long <- TSF_long %>% 
  group_by(Study_ID) %>% 
  distinct(Watershed, .keep_all = T) %>% 
  filter(Mean != 0) %>% 
  dplyr::select(Study_ID, Watershed, Mean)

count_TSF <- TSF_long %>% 
  count(Study_ID)
sum(count_TSF$n)# 57 watersheds are included in the TSF analysis 

 
ggplot(yearly_effect_size_combine_long, aes(Time_Since_Fire, Effect_size, color = response_var),
       position = position_dodge(width = -0.5)) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.4, size = 3) +
  geom_pointrange(aes(ymin = lower_ci_effect, ymax = upper_ci_effect,
                      color = response_var),
                  position = position_dodge(width = -0.5), size = 1.5, data = TSF_summary_effect) +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "red") +
  ylim(-3, 4) +
  ylab("Effect Size") +
  xlab("Year since Fire") +
  scale_color_manual(values = c("#00AFBB", "#E7B800"),
                     guide = guide_legend(title = "Analyte"),
                     labels = c('DOC', vn)) +
  stat_summary(fun.data = give.n, geom = "text", fun.y = median,
                  position = position_nudge(x = -0.4)) +
  scale_x_discrete(labels=c("0" = "Year of Fire", "1" = "1-2",
                            "2" = "2-3", "3" = "3-4", "4" = "4-5",
                            "5" = "5-6", ">10" = ">10")) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.17, 0.90))


ggsave("Effect_Size_TSF_Horizontal.pdf",
       path = here("initial_plots", "04_Meta_merge_all_studies_effect_size"),
       width = 10, height = 8, units = "in")



```


### Calculating percent difference ### 
```{r - plotting supplemental figures - scatterplot}
# For instance, on average, how much was DOC lower in the burned sites on a percent base and vice versa for nitrate?  - ALAN 


# Also, does effect size scale to % in some way? Cause effect size is harder for me to interpret, but if we can put a supplemental figure with percents and fit a line to NO3, we could get towards "as a rough approximation, NO3 increased across all sites by an estimated % per year. I guess we would need to use actual years since fire for that analysis, but might be cool if it fits nicely. Could use Sen-Theil slope since x-axis is time.
# effect_size <- read_csv("Output_for_analysis/Effect_Size_Geospatial_Fire_Lat_Long.csv")

percent_difference <- yearly_effect_size_combine_long %>% 
  mutate(pd = (100*(1-exp(Effect_size)))*-1) %>% 
  select(Study_ID, response_var, Effect_size_pair, Climate, Biome, Time_Since_Fire, Effect_size, pd) %>% 
  rename(Percent_Difference = pd)# creating percent difference 

write_csv(percent_difference, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "Percent_Difference.csv"))

# caculating confidence intervals # 

TSF_summary_effect <- percent_difference %>%
  group_by(Time_Since_Fire, response_var) %>%
  summarise(mean_effect = mean(Percent_Difference, na.rm = TRUE),
            sd_effect = sd(Percent_Difference, na.rm = TRUE),
            n_effect = n(),
            Percent_Difference = mean(Percent_Difference, na.rm = TRUE)) %>%
  mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect)

write_csv(TSF_summary_effect, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "TSF_PD_CIs.csv"))


# TSF 
ggplot(percent_difference, aes(Time_Since_Fire, Percent_Difference, color = response_var),
       position = position_dodge(width = -0.5)) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.4, size = 3) +
  geom_pointrange(aes(ymin = lower_ci_effect, ymax = upper_ci_effect,
                      color = response_var),
                  position = position_dodge(width = -0.5), size = 1.5, data = TSF_summary_effect) +
  scale_y_log10() +
  geom_hline(yintercept = 3000, linewidth = 0.5, color = "red") +
  ylab("Percent Difference") +
  xlab("Year since Fire") +
  scale_color_manual(values = c("#00AFBB", "#E7B800"),
                     guide = guide_legend(title = "Analyte"),
                     labels = c('DOC', vn)) +
  # stat_summary(fun.data = give.n, geom = "text", fun.y = median,
  #                 position = position_nudge(x = -0.4)) +
  scale_x_discrete(labels=c("0" = "Year of Fire", "1" = "1-2",
                            "2" = "2-3", "3" = "3-4", "4" = "4-5",
                            "5" = "5-6", ">10" = ">10")) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.17, 0.90))



# Scatter plot with linear regression for both DOC and nitrate 
ggplot(percent_difference, aes(Time_Since_Fire, Percent_Difference, color = response_var)) +
  geom_point() +
  geom_smooth(method = "lm")

percent_difference_test <- percent_difference %>% 
  mutate(Time_Since_Fire = as.numeric(Time_Since_Fire)) %>% 
  mutate(Time_Since_Fire = case_when(Study_ID == "Abbott et al. 2021" ~ 10,
                                     Study_ID == "Rhea et al. 2021" ~ 15,
                                     TRUE ~ Time_Since_Fire))

percent_difference_test %>% 
  filter(response_var == "DOC_Interp") %>% 
  filter(Time_Since_Fire < 7) %>% 
  ggplot(aes(Time_Since_Fire, Percent_Difference, color = response_var)) +
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label(c("eq", "R2")))

doc_filter <- percent_difference_test%>% 
  filter(response_var == "DOC_Interp") %>% 
  filter(Time_Since_Fire < 7)

doc <- percent_difference_test%>% 
  filter(response_var == "DOC_Interp")

write_csv(doc, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "TSF_PD_DOC_Fig_data.csv"))



lm.mod <- lm(Percent_Difference ~ Time_Since_Fire, data = doc_filter)
summary(lm.mod) # slope = -12.5

model <- theil_sen_regression(Percent_Difference ~ Time_Since_Fire, data = doc_filter)
summary(model) # slope = -6.991

model_full <- theil_sen_regression(Percent_Difference ~ Time_Since_Fire, data = doc)
summary(model_full) # slope = -3.153

# plot for supplemental # 
ggplot(doc_filter, aes(Time_Since_Fire, Percent_Difference, color = response_var)) +
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label(c("eq", "R2"))) +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "red") +
  ylab("Percent Difference") +
  xlab("Year since Fire") +
  scale_color_manual(values = c("#00AFBB" ),
                     guide = guide_legend(title = ""),
                     labels = c('DOC')) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.65, 0.90))

ggsave("DOC_Percent_Difference_Scatter.pdf",
       path = here("initial_plots", "04_Meta_merge_all_studies_effect_size"),
       width = 10, height = 8,  units = "in")

# no3
percent_difference_test %>% 
  filter(response_var == "NO3_Interp") %>% 
  ggplot(aes(Time_Since_Fire, Percent_Difference, color = response_var)) +
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label(c("eq", "R2")))
# slope = 62.1

no3 <- percent_difference_test%>% 
  filter(response_var == "NO3_Interp")

write_csv(no3, here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "TSF_PD_NO3_Fig_data.csv"))

no3_theil <- theil_sen_regression(Percent_Difference ~ Time_Since_Fire, data = no3)
summary(no3_theil) # Slope: 29.43

# plot for supplemental # 
ggplot(no3, aes(Time_Since_Fire, Percent_Difference, color = response_var)) +
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label(c("eq", "R2"))) +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "red") +
  ylab("Percent Difference") +
  xlab("Year since Fire") +
  scale_color_manual(values = c("#E7B800" ),
                     guide = guide_legend(title = ""),
                     labels = c(vn)) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.65, 0.90))

ggsave("NO3_Percent_Difference_Scatter.pdf",
       path = here("initial_plots", "04_Meta_merge_all_studies_effect_size"),
       width = 10, height = 8,  units = "in")

```































