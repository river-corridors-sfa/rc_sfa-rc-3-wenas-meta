---
title: "03_Wenas_effect_size"
output: html_document
date: "2023-07-11"
---

The purpose of this script is generate an output dataframe that is similar to Table 1 in Dove & Hart, 2017 (https://link.springer.com/article/10.4996/fireecology.130237746) that includes: 
Study_ID
Years since fire (TSF)
Climate 
control replicates (Nc)
control mean (Xc)
experimental replicates (Ne)
experimental mean (Xe) 
the natural log of the response ratio (ln[R])
Percent change (percent_change)
Percent change standard deviation (percent_changeSD)
effect size standard deviation (EsSD)
Difference (Diff)
AND 
Difference standard deviation (DiffSD) 
FOR EACH STUDY_ID

We also want to create a figure showing the variability of percent change between sites that have been burned compared to their reference site that is listed in the study_ID grouped put by TSF 

Workflow:
Step 1) Load in meta data sheet from googledrive located in "Fire numerical modeling Paper->Background Figure_MEBandVGC->Wenas_modeling_Papers_use_for_Fig"

Step 2) Clean spreadsheet to filter only data that is needed 

Step 3) Group by study_ID and obtain values listed above

Step 4) Save output file as: in "enter_directory filepath"

## Load packages and set working directory
```{r Jake/Mac}
#for Jake/mac

rm(list=ls(all=T)) #this clears your Environment

library(ggplot2)
library(googlesheets4)
library(tidyverse)
library(lubridate)
library(ggpubr)
```


### STEP 1 load in the data and filter out what columns we want ### 
```{r Metadata Google Sheet Import}
#import Metadata sheet that is stored on Google Sheet 
metadata <- read_sheet("https://docs.google.com/spreadsheets/d/1S1-Aheu-BJiIybye95YQzRi_9e2kS-udcsKcsC7H8dk/edit#gid=0",col_types ='c')

#you may need OAuth access. Press 1 to grant access

# select the columns that I want 
metadata <- metadata %>% select("Study_ID", "Pair_JSC", "Climate_JSC_from_climatecharts.net", 
                       "Burn or Unburn", "Time_Since_Fire", "Time_Since_Fire_JSC",
                 "DOC_mg_C_L", "STDEV_DOC", "STER_DOC",
                 "TN_mg_N_per_L", "STDEV_TN", "STER_TN",
                 "TDN_mg_N_per_L", "STDEV_TDN", "STER_TDN",
                 "NO3_mg_per_L_as_Nitrate", "STDEV_NO3", "STER_NO3",
                 "NH4_mg_per_L_as_NH4", "STER_NH4")

# rename some of the columns 
metadata <- metadata %>% 
    rename("Treatment" = "Burn or Unburn",
           "Koppen" = "Climate_JSC_from_climatecharts.net") 


# substituting all greater than or less than characters out 
# metadata <- metadata %>% 
#   mutate_all(str_remove(.,"<"))

metadata <- as.data.frame(sapply(metadata, gsub, pattern = "<|>", replacement = ""))

# making all concentraions numeric
metadata <- metadata %>% mutate_at(c("DOC_mg_C_L", "STDEV_DOC", "STER_DOC",
                               "TN_mg_N_per_L", "STDEV_TN", "STER_TN",
                               "TDN_mg_N_per_L", "STDEV_TDN", "STER_TDN",
                               "NO3_mg_per_L_as_Nitrate", "STDEV_NO3", "STER_NO3",
                               "NH4_mg_per_L_as_NH4", "STER_NH4"), as.numeric)

# Filter only post-burn/reference # study_ID 22 has some pre-burn and post-burn means that I want to ignore right now 
metadata <- metadata %>% 
  filter(Treatment == "Burn" | Treatment == "Unburn")

# Create a column that takes the time_since_fire column and mutates it into categorical buckets 
unique(metadata$Time_Since_Fire)

# BRIE advice for the below chunk #
# remove years using string remove 
# something within tidy to work with factors 
# look at the factors link in the chat 

# JSC solution to this mutate 
metadata <- metadata %>% 
  mutate(metadata, TSF = ifelse(grepl("12-13|13", Time_Since_Fire), ">10 years",
                              ifelse(grepl("6|7|8|9|10", Time_Since_Fire), "6-10 years",
                              ifelse(grepl("0|0-1|1", Time_Since_Fire), "0-1 years",
                              ifelse(grepl("2|3", Time_Since_Fire), "2-3 years",       
                              ifelse(grepl("4|5", Time_Since_Fire), "4-5 years",
                              ifelse(grepl("Pre-fire", Time_Since_Fire), "Pre-Fire",
                              ifelse(grepl("1-13 years post fire|Post-fire", Time_Since_Fire), "Post-Fire", "Other"))))))))

# No study ID's should be classified as Other #
unique(metadata$TSF)

# comparing to see if this above script actually worked 
a <- metadata$Time_Since_Fire
b <- metadata$TSF

c <- cbind(a,b)
```

#### STEP 2 calculate the means for each analyte by site  ### 
```{r Analyte summary stats}

# pivoting to make the responses in one column
metadata_long <- metadata %>% 
  pivot_longer(
    cols = DOC_mg_C_L:STER_NH4,
    names_to = "response_var",
    values_to = "mean_concentration",
    values_drop_na = TRUE
  )

# calculating the mean of all the burns and all the controls by analyte for each study #
MeanConcTest <- metadata_long %>%
  group_by(Study_ID, Pair_JSC, Treatment, response_var, Koppen, TSF) %>%
  dplyr::summarize(Ne = sum(Treatment == "Burn"),
                   Nc = sum(Treatment == "Unburn"),
                   Xe = mean(mean_concentration[Treatment == "Burn"], na.rm = TRUE),
                   Xc = mean(mean_concentration[Treatment == "Unburn"], na.rm = TRUE))




# This is calculating the mean for EACH site within a study_ID # 
    # Any study_ID that doesn't have up to 10 sites will have a 0 in the respective Xen column 
analyte_table_means <- MeanConcTest %>%
  select(-Pair_JSC) %>%
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  summarize(Ne = sum(Ne),
            Nc = sum(Nc),
            Xe1 = sum(Xe[Pair_JSC == "Site 1"], na.rm = TRUE),
            Xe2 = sum(Xe[Pair_JSC == "Site 2"], na.rm = TRUE),
            Xe3 = sum(Xe[Pair_JSC == "Site 3"], na.rm = TRUE),
            Xe4 = sum(Xe[Pair_JSC == "Site 4"], na.rm = TRUE),
            Xe5 = sum(Xe[Pair_JSC == "Site 5"], na.rm = TRUE),
            Xe6 = sum(Xe[Pair_JSC == "Site 6"], na.rm = TRUE),
            Xe7 = sum(Xe[Pair_JSC == "Site 7"], na.rm = TRUE),
            Xe8 = sum(Xe[Pair_JSC == "Site 8"], na.rm = TRUE),
            Xe9 = sum(Xe[Pair_JSC == "Site 9"], na.rm = TRUE),
            Xe10 = sum(Xe[Pair_JSC == "Site 10"], na.rm = TRUE),
            Xc = sum(Xc[Pair_JSC == "Control"], na.rm = TRUE)) 

# making all the cells with 0 due to no sites beyond what the study had NAs to visualize the dataframe a little better. 
analyte_table_means[analyte_table_means == 0] <- NA

# This chunk is calculating the percent_change between the sites and the control. 
# study_ID 12 is the ONLY site with multiple controls. SO I am filtering it out for now:


# This is doing the same thing as analyte_table_means chunk but adding in the multiple controls for study_ID_12

brie_test <- MeanConcTest %>% 
  filter(Study_ID == "12") %>% 
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  summarize(Xe1 = sum(Xe[Pair_JSC == "Site 1"], na.rm = TRUE),
            Xe2 = sum(Xe[Pair_JSC == "Site 2"], na.rm = TRUE),
            Xe3 = sum(Xe[Pair_JSC == "Site 3"], na.rm = TRUE),
            Xe4 = sum(Xe[Pair_JSC == "Site 4"], na.rm = TRUE),
            Xe5 = sum(Xe[Pair_JSC == "Site 5"], na.rm = TRUE),
            Xc123 = sum(Xc[Pair_JSC == "Control 1, 2, and 3"], na.rm = TRUE),
            Xc4 = sum(Xc[Pair_JSC == "Control 4"], na.rm = TRUE),
            Xc5 = sum(Xc[Pair_JSC == "Control 5"], na.rm = TRUE)) 


# Calculating effect size: ln((MeanTreatment/MeanControl))
analyte_table_effect_size <- analyte_table_means %>% 
  filter(Study_ID != "12", Study_ID != "9") %>% 
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  mutate(lnR1 = log(Xe1/Xc),
         lnR2 = log(Xe2/Xc),
         lnR3 = log(Xe3/Xc),
         lnR4 = log(Xe4/Xc),
         lnR5 = log(Xe5/Xc),
         lnR6 = log(Xe6/Xc),
         lnR7 = log(Xe7/Xc),
         lnR8 = log(Xe8/Xc),
         lnR9 = log(Xe9/Xc),
         lnR10 = log(Xe10/Xc))

brie_test_stats_effect <- brie_test %>% 
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  mutate(lnR1 = log(Xe1/Xc123),
         lnR2 = log(Xe2/Xc123),
         lnR3 = log(Xe3/Xc123),
         lnR4 = log(Xe4/Xc4),
         lnR5 = log(Xe5/Xc5)) %>% 
  add_column(Ne = NA,
             Nc = NA,
             Xe6 = NA,
             Xe7 = NA,
             Xe8 = NA,
             Xe9 = NA,
             Xe10 = NA,
             Xc = NA,
             lnR6 = NA,
             lnR7 = NA,
             lnR8 = NA,
             lnR9 = NA,
             lnR10 = NA) %>% 
  ungroup()

# Adding columns to match brie_test_stats
analyte_table_effect_size <-analyte_table_effect_size %>% 
  add_column(Xc123 = NA,
             Xc4 = NA,
             Xc5 = NA) %>% 
  ungroup()

# combining study_ID_12 back into the mix 
analyte_table_combine_effect_size <- analyte_table_effect_size %>% 
  add_row(brie_test_stats_effect)

## Study_ID_9 ##
# Study_ID 9 is not working properly, so let me try and fix it here: #
study_9 <- MeanConcTest %>% 
  filter(Study_ID == 9) %>% 
  filter(response_var == "DOC_mg_C_L" | 
         response_var == "NO3_mg_per_L_as_Nitrate")

analyte_table_means_9 <- study_9 %>% 
  select(-Pair_JSC) %>%
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  summarize(Ne = sum(Ne),
            Nc = sum(Nc),
            Xe1 = sum(Xe[Pair_JSC == "Site 1"], na.rm = TRUE),
            Xe2 = sum(Xe[Pair_JSC == "Site 2"], na.rm = TRUE),
            Xe3 = sum(Xe[Pair_JSC == "Site 3"], na.rm = TRUE),
            Xe4 = sum(Xe[Pair_JSC == "Site 4"], na.rm = TRUE),
            Xe5 = sum(Xe[Pair_JSC == "Site 5"], na.rm = TRUE),
            Xe6 = sum(Xe[Pair_JSC == "Site 6"], na.rm = TRUE),
            Xe7 = sum(Xe[Pair_JSC == "Site 7"], na.rm = TRUE),
            Xe8 = sum(Xe[Pair_JSC == "Site 8"], na.rm = TRUE),
            Xe9 = sum(Xe[Pair_JSC == "Site 9"], na.rm = TRUE),
            Xe10 = sum(Xe[Pair_JSC == "Site 10"], na.rm = TRUE),
            Xc = sum(Xc[Pair_JSC == "Control"], na.rm = TRUE)) 

analyte_table_means_9$Xc[analyte_table_means_9$response_var == "DOC_mg_C_L" &
                                                  analyte_table_means_9$Xc=="0"]<- 2.14

analyte_table_means_9$Xc[analyte_table_means_9$response_var == "NO3_mg_per_L_as_Nitrate" &
                                                  analyte_table_means_9$Xc=="0"]<- 0.006774194

analyte_table_means_9[analyte_table_means_9 == 0] <- NA

effect_size_9 <- analyte_table_means_9 %>% 
  group_by(Study_ID, response_var, Koppen, TSF) %>%
  mutate(lnR1 = log(Xe1/Xc),
         lnR2 = log(Xe2/Xc),
         lnR3 = log(Xe3/Xc),
         lnR4 = log(Xe4/Xc),
         lnR5 = log(Xe5/Xc),
         lnR6 = log(Xe6/Xc),
         lnR7 = log(Xe7/Xc),
         lnR8 = log(Xe8/Xc),
         lnR9 = log(Xe9/Xc),
         lnR10 = log(Xe10/Xc))

analyte_table_combine_effect_size <- analyte_table_combine_effect_size %>% 
  add_row(effect_size_9)

# Adding a broader climate variable that will group the codes into climates that people actually understand #
unique(analyte_table_combine_effect_size$Koppen)

analyte_table_combine_effect_size <- analyte_table_combine_effect_size %>% 
  mutate(analyte_table_combine_effect_size, Climate = ifelse(grepl("Dfb|Dfc|Dsc", Koppen), "Cold",
                              ifelse(grepl("Cfb|Csa|Csb", Koppen), "Temperate",
                              ifelse(grepl("BSk", Koppen), "Arid",
                              ifelse(grepl("As|Af|Am", Koppen), "Tropical",
                              ifelse(grepl("ET|EF", Koppen), "Polar", "Other"))))))

# export dataframe 
write.csv(analyte_table_combine_effect_size, "~/GitHub/rc_sfa-rc-3-wenas-modeling/Lit_Review_Fig/Output_for_analysis/analyte_table_effect_size.csv", row.names=FALSE)


# pivoting to make the responses in one column
# effect size 
analyte_table_long_effect <- analyte_table_combine_effect_size %>% 
  pivot_longer(
    cols = lnR1:lnR10,
    names_to = "Site",
    values_to = "Effect_size",
    values_drop_na = TRUE
  )

# filter out the only analytes that we want to include in the figure 
# effect size 
analyte_table_filter_effect <- analyte_table_long_effect %>% 
  filter(response_var == "DOC_mg_C_L"| response_var == "NO3_mg_per_L_as_Nitrate")

# export dataframe 

write.csv(analyte_table_filter_effect, "~/GitHub/rc_sfa-rc-3-wenas-modeling/Lit_Review_Fig/Output_for_analysis/analyte_table_effect_DOC_no3.csv", row.names=FALSE)

# I want to pivot_longer to make all means in one column
# pivoting to make the responses in one column
analyte_table_long_2 <- analyte_table_filter_effect %>%
  pivot_longer(
    cols = Xe1:Xc5,
    names_to = "Stats",
    values_to = "Value",
    values_drop_na = TRUE
  )

# Calculating a confidence interval for all of the effect sizes
# calculating the mean percent_difference by climate
climate_summary_effect <- analyte_table_filter_effect %>%
  group_by(Koppen, response_var, Climate) %>%
  summarise(mean_effect = mean(Effect_size, na.rm = TRUE),
            sd_effect = sd(Effect_size, na.rm = TRUE),
            n_effect = n()) %>%
  mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect)


# Calculating a confidence interval for all of the effect sizes
# calculating the mean effect_size by climate
TSF_summary_effect <- effect_size %>%
  group_by(TSF, response_var) %>%
  summarise(mean_effect = mean(Effect_size, na.rm = TRUE),
            sd_effect = sd(Effect_size, na.rm = TRUE),
            n_effect = n()) %>%
  mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect)







```


```{r}
### STEP 3 Plotting ###

# Ploting #
vn = expression(paste(""*N*O[3]^"-"))

# geom_jitter for climate # 
ggplot(analyte_table_filter, aes(Percent_Difference, Koppen, color = response_var),
              position = position_dodge(width = -0.5)) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.4, size = 3) +
  geom_pointrange(aes(xmin = Percent_Difference - sd, xmax = Percent_Difference + sd, 
                      color = response_var),
                      position = position_dodge(width = -0.5), size = 1.5, data = climate.summary) +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "red") +
  xlim(-100, 700) +
  ylab("Koppen (Climate Classification)") +
  xlab("Percent Difference (%)") +
  geom_segment(aes(x = 500, xend = 500, y = 6.5, yend = 4.5), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 6.5, yend = 6.5), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 4.5, yend = 4.5), color = "black") +
  
  geom_segment(aes(x = 500, xend = 500, y = 4.3, yend = 1.5), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 4.3, yend = 4.3), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 1.5, yend = 1.5), color = "black") +
   
  geom_segment(aes(x = 500, xend = 500, y = 1.3, yend = 0.5), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 1.3, yend = 1.3), color = "black") +
  geom_segment(aes(x = 475, xend = 500, y = 0.5, yend = 0.5), color = "black") +
  annotate("text",
           x = c(550, 550, 550),
           y = c(5.5, 3, 1),
           label = c("Cold", "Temperate", "Arid"),
           family = "", fontface = "bold") +
  scale_color_manual(values = c("#00AFBB", "#E7B800"),
                     guide = guide_legend(title = "Analyte"),
                     labels = c('DOC', vn)) +
  theme_classic() +
  theme(axis.text.x = element_text(size = 30),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.position = c(0.9, 0.65))

ggsave("site.difference.geom_pointrange.climate.pdf",
       path = ("~/GitHub/rc_sfa-rc-3-wenas-modeling/Lit_Review_Fig/initial_plots/01_Wenas_lit_review_figure"),
       width = 10, height = 8, units = "in")






```


