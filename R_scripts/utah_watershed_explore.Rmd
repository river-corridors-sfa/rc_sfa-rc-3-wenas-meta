---
title: "Utah_watersheds_explore"
output: html_document
date: "2024-07-02"
editor_options: 
  chunk_output_type: inline
---

# Status: in progress

# ==============================================================================
# Author: Kathryn Willi & Matthew R. V. Ross: https://doi.org/10.5281/zenodo.8140272

# Adapted by Jake Cavaiani for the manuscript: Catchment characteristics modulate the influence of wildfires on nitrate and dissolved organic carbon across space and time: A meta-analysis; jake.cavaiani@pnnl.gov

# 30 October 2023
# ==============================================================================


```{r setup, include=TRUE, echo = T, warning = F, comment = F, message = FALSE}
rm(list=ls(all=T))
library(sf)
library(tidyverse)
library(terra)
library(nhdplusTools)
library(mapview)
library(here)
library(dataRetrieval)
library(lubridate)
library(prism)
library(ggspatial)
library(nngeo)# Added from original code
library(stars)# Added from original code
# this gives you an error, but it can be ignored:
try(plyr::ldply(list.files(path = here("R_scripts", "data", "src"),
                           pattern="*.R",
                           full.names=TRUE),
                source))
# Rmarkdown options
knitr::opts_chunk$set(echo = T, warning = F, comment = F, message = F)

# mapview options
mapviewOptions(basemaps.color.shuffle=FALSE,basemaps='OpenTopoMap')
```

### Setting up your site data set.

For this code to run properly, your site data must be configured as follows:

1)  Each site is identified with a unique site name. In the data set, this column must be called `site`.
2)  Each site has their known COMID, with column name `comid`. 
4)  Site data table is a CSV, and stored in the `data/` folder. 


#### Downloading necessary data sets

Currently, this workflow requires downloading several data sets locally for much speedier run times. This includes: PRISM climate & aridity rasters, NHD flow direction data, and CONUS-wide NHD catchments. All data sets are found in the shared `data` folder.


# National Hydrodraphy Dataset (NHD) data extraction

Use COMID to allow site linkages with all datasets in this workflow. 

```{r}
sf_use_s2(FALSE)

site_type = "xy" # OR site_type = "comid"

sites <- read_csv(here("inputs", "catchment_characteristics", "watershed_lat_long.csv"), na = c('-9999', 'N/A')) %>%
  distinct(Site, .keep_all = TRUE) %>%
  dplyr::select('Site','latitude','longitude') %>% 
  rename(site = Site) %>% 
  drop_na()

sites <- sites %>% 
  filter(site %in% c("Benjamin_Slough", "Payson"))

```


Pull all meta data associated with each site's COMID. 

```{r}
if(site_type == "xy"){
  sites <- sites %>%
    dplyr::select(site, latitude, longitude) %>% 
    sf::st_as_sf(coords = c("longitude","latitude"), crs = 4269) # 4269 = NAD83 CRS
  
  if(sf::st_crs(sites) != sf::st_crs(4269)){
    sites <- sites %>% st_transform(., crs = 4269)
  }
  
  mapview(sites)
}
```

```{r}
if(site_type == "xy"){
  sites <- getNHDxy(df = sites)
}

```

Make NHD-based watershed shapefiles for all CONUS sites. To make this step MUCH faster, it is best to have a locally downloaded version on the National NHD catchment shapefile stored on your local system. I have already included this shapefile in the `data` folder. 

```{r}
site_watersheds <- getWatersheds(df = sites, make_pretty = TRUE) %>%
  inner_join(., dplyr::select(sf::st_drop_geometry(sites), site, comid), by = "comid")
```


Map all your sites. Maps are automatically stored in the `data/maps/` folder. It is highly recommended to review each map, particularly for known locations along BIG rivers and TINY streams.Note: COMIDs should have been checked before running this code. 

```{r}
map2(sites$site, sites$comid, getMaps) 
```

Interactive map showing all sites and their delineated watersheds:

```{r}
mapview(site_watersheds, col.regions = "#56B4E9", alpha.regions = 0.2, lwd = 3, layer.name = "Watershed") +
  mapview(sites, cex = 5, col.regions = "black", layer.name = "Points") + 
  mapview(st_read('data/site_flowlines.gpkg', quiet = T), lwd = 3, color = "red", layer.name = "Flowline")
```

# ================== Manually changing the lat long of the sites ==================
```{r}
sites <- read_csv(here("inputs", "catchment_characteristics", "watershed_lat_long.csv"), na = c('-9999', 'N/A')) %>%
  distinct(Site, .keep_all = TRUE) %>%
  dplyr::select('Site','latitude','longitude') %>% 
  rename(site = Site) %>% 
  drop_na()

sites <- sites %>% 
  filter(site %in% c("Benjamin_Slough", "Payson"))

# Change the coordinates for Benjamin Slough 
sites <- sites %>% 
  mutate(latitude = case_when(site == "Benjamin_Slough" ~ 40.097765,
                                       TRUE ~ latitude),
         longitude = case_when(site == "Benjamin_Slough" ~ -111.775882,
                                       TRUE ~ longitude))

if(site_type == "xy"){
  sites <- sites %>%
    dplyr::select(site, latitude, longitude) %>% 
    sf::st_as_sf(coords = c("longitude","latitude"), crs = 4269) # 4269 = NAD83 CRS
  
  if(sf::st_crs(sites) != sf::st_crs(4269)){
    sites <- sites %>% st_transform(., crs = 4269)
  }
  
  mapview(sites)
}

if(site_type == "xy"){
  sites <- getNHDxy(df = sites)
}

site_watersheds <- getWatersheds(df = sites, make_pretty = TRUE) %>%
  inner_join(., dplyr::select(sf::st_drop_geometry(sites), site, comid), by = "comid")

mapview(site_watersheds, col.regions = "#56B4E9", alpha.regions = 0.2, lwd = 3, layer.name = "Watershed") +
  mapview(sites, cex = 5, col.regions = "black", layer.name = "Points") + 
  mapview(st_read('data/site_flowlines.gpkg', quiet = T), lwd = 3, color = "red", layer.name = "Flowline")

```
```{r}
sus_points <- sites 
  # Comment the line below if you want to remove some sites:
  # %>%
  #filter(site %in% c("site_name","sine_name2"))

sus_nhd <- sus_points %>%
  sf::st_buffer(., dist = 0.01) %>%
  sus_mapper(.)


mapview(sus_nhd[[2]], col.regions = "#56B4E9", alpha.regions = 0.4, legend = FALSE) +
 # mapview(sbux_sf, cex = 5, col.regions = "red", legend = FALSE) +
  mapview(sus_points, cex = 5, col.regions = "black", legend = FALSE) +
  mapview(sus_nhd[[1]], lwd = 1.5, color = "red", legend = FALSE)
```
```{r}
# Benjamin Slough is currently: 10349126
# Benjamin Slough could be any of these based on this lat/long:
# 10349212 - NOPE
# 10349160 - Similar to the first comid
# 10349142 - Similar to the first comid
# 10349100 - Similar to the first comid
# 10349048
updated_sites <- tibble(site = c("Benjamin_Slough", "Payson"),comid = c(	
10349126, 10350360)) 
# Payson from Crandall paper is supposed to be COMID: 10350360

sites <- updated_sites %>% 
  getNHDcomid(.) %>% 
  bind_rows(filter(sites, site %in% sus_points$site)) %>% 
  distinct(site, .keep_all = TRUE)

# sites <- sites %>% 
#   dplyr::select(site, comid, totdasqkm, minelevraw, maxelevsmo, minelevsmo, elevfixed, slope) %>% 
#   rename(Site = site)

# Updated site_watersheds
site_watersheds <- getWatersheds(df = sites, make_pretty = TRUE) %>%
  inner_join(., dplyr::select(sf::st_drop_geometry(sites), site, comid), by = "comid")

mapview(site_watersheds, col.regions = "#56B4E9", alpha.regions = 0.2, lwd = 3, layer.name = "Watershed") +
  mapview(sites, cex = 5, col.regions = "black", layer.name = "Points") + 
  mapview(st_read('data/site_flowlines.gpkg', quiet = T), lwd = 3, color = "red", layer.name = "Flowline")

```

# ============== Manually clip the watershed out and get the COMID =====================
```{r}
library(sf)

# Read the data
watershed_shape <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/watershed_shapefile.shp") %>%
    filter(site %in% c("Payson", "Benjamin_Slough"))

large_watershed <- watershed_shape %>% 
  filter(site == "Benjamin_Slough")

# Plot
ggplot() +
  geom_sf(data = large_watershed, fill = "#56B4E9", alpha = 0.2, color = "black") +
  theme_minimal()


small_watershed <- watershed_shape %>% 
  filter(site == "Payson")

# Plot
ggplot() +
  geom_sf(data = small_watershed, fill = "#56B4E9", alpha = 0.2, color = "black") +
  theme_minimal()

# Latitude and longitude coordinates for points within the watersheds
lat_large <- 40.134567
lon_large <- -111.791953
lat_small <- 39.974595
lon_small <- -111.702362

# Create points
point_large <- st_sfc(st_point(c(lon_large, lat_large)), crs = st_crs(large_watershed))
point_small <- st_sfc(st_point(c(lon_small, lat_small)), crs = st_crs(small_watershed))

# Convert points to sf objects
point_large_sf <- st_sf(geometry = point_large)
point_small_sf <- st_sf(geometry = point_small)

# Ensure both watersheds have the same CRS
large_watershed <- st_transform(large_watershed, crs = st_crs(small_watershed))

# Clip the smaller watershed out of the larger one
clipped_watershed <- st_difference(large_watershed, small_watershed)

# Print the clipped watershed to check the result
print(clipped_watershed)

# Plot
ggplot() +
  geom_sf(data = large_watershed, fill = "#56B4E9", alpha = 0.2, color = "#56B4E9") +
  geom_sf(data = small_watershed, fill = "red", alpha = 0.2, color = "red") +
  geom_sf(data = clipped_watershed, fill = "green", alpha = 0.1, color = "green") +
  theme_minimal()

# Export clipped watershed as shape file
st_write(clipped_watershed, "~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/clipped_watershed_shapefile.shp")


# Read the flow network CSV
flow_network <- read_csv("~/GitHub/rc_sfa-rc-3-wenas-meta/R_scripts/data/nhd_flow_network.csv")

# Example assuming the flow network has columns like 'FromNode' and 'ToNode'
# Convert these to spatial points (dummy example)
# Replace with actual logic to identify relevant segments

# Create spatial points from FromNode and ToNode (dummy example)
flow_network_sf <- flow_network %>%
  st_as_sf(coords = c("FromNode", "ToNode"), crs = 4326)

# Ensure the flow network has a valid CRS (use your actual CRS if known)
st_crs(flow_network_sf) <- st_crs(large_watershed)

# Placeholder function to identify COMIDs within a clipped watershed
identify_comids_in_clipped <- function(flow_network_sf, clipped_watershed) {
  # Perform a spatial join or filtering based on your specific criteria
  # Example: filtering based on points within the clipped watershed
  clipped_segments <- st_intersection(flow_network_sf, clipped_watershed)
  
  # Extract and return COMIDs or relevant identifiers
  return(clipped_segments$COMID)
}

# Call the function to identify COMIDs within the clipped watershed
clipped_comids <- identify_comids_in_clipped(flow_network_sf, clipped_watershed)


```


## View sites and adjacent COMIDs

If after reviewing the delineated watersheds you have found that some site coordinates place that location in the wrong catchment, we will need to explore that site's nearby catchments to link it to the correct COMID:

```{r}
sus_points <- sites 
  # Comment the line below if you want to remove some sites:
  # %>%
  #filter(site %in% c("site_name","sine_name2"))

sus_nhd <- sus_points %>%
  sf::st_buffer(., dist = 0.01) %>%
  sus_mapper(.)


mapview(sus_nhd[[2]], col.regions = "#56B4E9", alpha.regions = 0.4, legend = FALSE) +
 # mapview(sbux_sf, cex = 5, col.regions = "red", legend = FALSE) +
  mapview(sus_points, cex = 5, col.regions = "black", legend = FALSE) +
  mapview(sus_nhd[[1]], lwd = 1.5, color = "red", legend = FALSE)
```

## In the table below, add sites and their correct comid's

```{r}
# # Based on the map, it appears that this site should be linked to comid a different comid

updated_sites <- tibble(site = c("Benjamin_Slough", "Payson"),comid = c(10329195, 10350360)) 
# Payson from Crandall paper is supposed to be COMID: 10350360


sites <- updated_sites %>% 
  getNHDcomid(.) %>% 
  bind_rows(filter(sites, site %in% sus_points$site)) %>% 
  distinct(site, .keep_all = TRUE)

# sites <- sites %>% 
#   dplyr::select(site, comid, totdasqkm, minelevraw, maxelevsmo, minelevsmo, elevfixed, slope) %>% 
#   rename(Site = site)

# Updated site_watersheds
site_watersheds <- getWatersheds(df = sites, make_pretty = TRUE) %>%
  inner_join(., dplyr::select(sf::st_drop_geometry(sites), site, comid), by = "comid")

```

Updated Comids map

```{r}
mapview(site_watersheds, col.regions = "#56B4E9", alpha.regions = 0.2, lwd = 3, layer.name = "Watershed") +
  mapview(sites, cex = 5, col.regions = "black", layer.name = "Points") + 
  mapview(st_read('data/site_flowlines.gpkg', quiet = T), lwd = 3, color = "red", layer.name = "Flowline")
```

```{r export COMIDs}
site_type = "comid"

if(site_type == "comid"){
  sites <- getNHDcomid(df = dplyr::select(sites, site, comid))
}


sites_export <- sites %>%
  select(site, latitude, longitude, comid)

write_csv(sites_export, here("inputs", "catchment_characteristics", "meta_lat_long_comids.csv"))

```
