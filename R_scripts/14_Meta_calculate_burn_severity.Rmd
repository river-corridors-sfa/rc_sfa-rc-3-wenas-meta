---
title: "14_Meta_calculate_burn_severity"
output: html_document
date: "2024-06-12"
editor_options: 
  chunk_output_type: console
---

The purpose of this script is to get the average DNBR within a basin area using MTBS raster of burn severity and the watershed boundary. This code is adapted from Katie Wampler where you calculate the average dNBR of each fire perimeter within a watershed boundary and that average value is used to categorize the burn severity as "Low Severity", "Moderate Severity", "High Severity".

Script inputs:
  1) dNBR raster of fires
  2) Shape files of each watershed boundary


#written by Katie A. Wampler on 2024-06-12 


# Status: in progress

# ==============================================================================
# Author: Katie Wampler
#     Adapted by Jake Cavaiani; jake.cavaiani@pnnl.gov
# 12 June 2024
# ==============================================================================

# load libraries and functions
```{r Load packages}
#for Jake/mac

rm(list=ls(all=T)) #this clears your Environment

library(dplyr)
library(raster)
library(sf)
library(exactextractr)
library(readr)
library(here)
library(nhdplusTools) # used to pull basin for analysis 
library(purrr)
library(stringr)
library(ggplot2)

```

# Convert crs function 
```{r crs function}
convert_crs <- function (input, goal, type = "numeric", res = NULL) 
{
    stopifnot(class(input)[1] %in% c("sf", "RasterLayer"), class(goal)[1] %in% 
        c("sf", "RasterLayer"), type %in% c("numeric", "categorical"))
    if (raster::compareCRS(goal, input) == T) {
        message("CRS already matches that of your goal object")
        return(input)
    }
    else {
        if (class(input)[1] == "RasterLayer") {
            if (is.null(res)) {
                if (class(goal)[1] == "RasterLayer") {
                  res <- terra::res(goal)[1]
                }
                else {
                  unit <- sf::st_crs(goal, parameters = TRUE)$units_gdal
                  res <- ifelse(unit == "degree", 0.0003280119, 
                    30)
                }
            }
            method <- ifelse(type == "numeric", "bilinear", "ngb")
            input_prj <- raster::projectRaster(input, crs = raster::crs(goal), 
                method = method, res = res)
        }
        else {
            input_prj <- sf::st_transform(input, raster::crs(goal))
        }
        return(input_prj)
    }
}

```

# Function to clip raster to a shapefile 
```{r function}
# This function will ensure the projection is the same between the raster the shapefile and then clip the raster to the basin boundry. It can return a raster (for further analysis) or a dataframe (for plotting)

#' @param raster the raster you want to clip
#' @param sf the shapefile you want to use to clip the raster
#' @param type either 'numeric' or 'categorical' depending on if your raster is discrete or continuous values
#' @param res the resolution of the projected raster, if not specified with default to 30m
#' @param return either 'df' or 'raster' to specify the form of the returned raster
#'
#' @return if 'return' is df it will return the raster as a dataframe suitable 
#' for plotting in ggplot2. If 'return' is raster it will return the raster as a rasterLayer object

clean_raster <- function (raster, sf, type = "numeric", 
                            res = NULL, return = "df") {stopifnot(class(raster) == "RasterLayer", class(sf)[1] == 
                c("sf"), type %in% c("numeric", "categorical"), return %in% 
                c("df", "raster"))
    unit <- sf::st_crs(sf, parameters = TRUE)$units_gdal
    buffer <- ifelse(unit == "degree", 0.1, 5000)
    res <- ifelse(unit == "degree", 0.0003280119, 30)
    method <- ifelse(type == "numeric", "bilinear", "ngb")
    if (compareCRS(raster, sf) == T) {
      raster_crop <- raster::crop(raster, sf)
      raster_crop <- raster::mask(raster_crop, sf)
      raster_df <- as.data.frame(raster::rasterToPoints(raster_crop))
      colnames(raster_df) <- c("x", "y", "val")
    }
    else {
      sf_prj <- convert_crs(sf::st_buffer(sf, dist = buffer), 
                            raster)
      raster_crop <- raster::crop(raster, sf_prj)
      raster_crop <- raster::mask(raster_crop, sf_prj)
      raster_prj <- raster::projectRaster(raster_crop, crs = crs(sf), 
                                          method = method, res = res)
      raster_crop <- raster::crop(raster_prj, sf)
      raster_crop <- raster::mask(raster_crop, sf)
      raster_df <- as.data.frame(raster::rasterToPoints(raster_crop))
      colnames(raster_df) <- c("x", "y", "val")
    }
    if (return == "df") {
      raster_df
    }
    else {
      raster_crop
    }
} 

```

# ==================================== for loop  ===============================

```{r}
# Read in site shapefiles
site_shape <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/watershed_shapefile.shp")

# Add location of the fire in the data frame
fire_names <- read_csv(here("inputs", "catchment_characteristics", "fire_watershed_lat_long_comids.csv")) %>%
  dplyr::select(site = Site, comid, fire_name, fire_year, mtbs_id)

fire_names <- fire_names %>%
  mutate(fire_name = str_to_lower(fire_name))

# Add columns for file paths to the fire_names data frame
fire_names <- fire_names %>%
  mutate(
    dnbr_path = paste0("gis_data/Fire_Perimeters/", fire_name, "/mtbs/", fire_year, "/", mtbs_id, "/", fire_name, "_dnbr.tif"),
    fire_shape_path = paste0("gis_data/Fire_Perimeters/", fire_name, "/mtbs/", fire_year, "/", mtbs_id, "/", fire_name, "_burn_bndy.shp")
  )

# Join the site shape and fire names data
site_shape_fire_combined <- full_join(site_shape, fire_names)

# site_shape_fire_combined <- site_shape_fire_combined %>% 
#   filter(fire_name == "gaviota")

# Initialize the results data frame
burn_severity <- tibble(
  site = character(),
  fire_name = character(),
  mean_dnbr = numeric())

# Read in thresholds data frame
thresholds <- read_csv(here("Output_for_analysis", "13_Meta_calculate_thresholds_per_fire", "Fire_thresholds.csv")) %>% 
  dplyr::select(!zone) %>% 
  dplyr::select(!...1)

# Iterate through each site in the combined shapefile
for (i in 1:nrow(site_shape_fire_combined)) {
  # Get the site name, fire name, and file paths
  site_name <- site_shape_fire_combined$site[i]
 
  fire_name <- site_shape_fire_combined$fire_name[i]
  dnbr_path <- site_shape_fire_combined$dnbr_path[i]
  fire_shape_path <- site_shape_fire_combined$fire_shape_path[i] 
  
  if (file.exists(here(dnbr_path)) && file.exists(here(fire_shape_path))) {
    # Load the corresponding dnbr raster and fire shapefile
    dnbr <- raster(here(dnbr_path))
    plot(dnbr)
    
  
    fire_shape <- st_read(here(fire_shape_path))
    plot(fire_shape)
    
    # Clip the dNBR data to the fire boundary
    dnbr <- mask(dnbr, st_as_sf(fire_shape))
    plot(dnbr)
    
    # Get the watershed boundary
    watershed_boundary <- site_shape_fire_combined[i, ]
    plot(watershed_boundary)
    
    # Ensure the CRS of the layers are compatible
    if (!st_crs(watershed_boundary) == crs(dnbr)) {
      watershed_boundary <- st_transform(watershed_boundary, crs(dnbr))
    }
    
    # Clip the dNBR data to the watershed boundary
    dnbr_clipped <- mask(dnbr, st_as_sf(watershed_boundary))
    plot(dnbr_clipped)
    # Extract data and calculate the mean dNBR
    mean_dnbr_value <- exactextractr::exact_extract(dnbr_clipped, watershed_boundary, "mean", progress = FALSE)
    
    # Add a new row to the dataframe
    burn_severity <- burn_severity %>%
      add_row(
        site = site_name,  # use the scalar value directly
        fire_name = fire_name,  # use the scalar value directly
        mean_dnbr = mean_dnbr_value
      )
  
  }
}

# Merge burn_severity with thresholds on fire_name
burn_severity_thresholds <- burn_severity %>%
  left_join(thresholds, by = "fire_name")

# Calculate the burn severity category based on mean dNBR and thresholds
burn_severity_thresholds <- burn_severity_thresholds %>%
  rowwise() %>%
  mutate(
    burn_severity_category = case_when(
      mean_dnbr >= min & mean_dnbr <= max ~ Burn_Severity,
      TRUE ~ NA_character_
    )
  ) %>%
  ungroup()

```

```{make final burn severity data frame}

# Group by site and fire_name, and select the desired columns
final_burn_severity <- burn_severity_thresholds %>%
  group_by(site, fire_name) %>%
  summarize(
    mean_dnbr = mean(mean_dnbr, na.rm = TRUE),
    burn_severity_category = first(burn_severity_category[!is.na(burn_severity_category)])
  ) %>%
  ungroup()

# Print the results
print(final_burn_severity)

# rename Site
final_burn_severity <- final_burn_severity %>% 
  rename(Site = site) %>% 
  mutate(Site = str_replace_all(Site, "_", " "))
  

# Read in the study and site csv 
# Murphy et al. 2015 data is incorporated in Murphy et al. 2018 data
study_site_data <- read_csv(here("inputs", "catchment_characteristics", "Fire_name_Lat_Long.csv"), na = c('-9999', 'N/A')) %>% 
  dplyr::select(Study_ID, Site, Fire_year, Effect_size_pair, burn_percentage) %>% 
  rename(year = Fire_year) %>% 
  mutate(Site = str_replace_all(Site, "_", " ")) %>% 
  filter(!Study_ID == "Murphy et al. 2015") %>% 
  na.omit()

# merge 
site_burn_severity <- full_join(final_burn_severity, study_site_data) %>% 
  dplyr::select(Study_ID, Site, fire_name, year, Effect_size_pair, mean_dnbr, burn_severity_category, burn_percentage) %>% 
  na.omit(Effect_size_pair)


# write_csv(final_burn_severity, here("Output_for_analysis", "14_Meta_calculate_burn_severity", "DNBR_Severity.csv"))


```


```{r read in effect size and merge dataframes}
# The effect sizes of each study's watershed
effect_size <- read_csv(here("Output_for_analysis", "04_Meta_merge_all_studies_effect_size", "Effect_Size.csv"), na = c('-9999', 'N/A')) %>% 
  dplyr::select(Study_ID, response_var, Climate, Biome, Effect_size, Effect_size_pair, Time_Since_Fire) %>% 
  filter(!Study_ID == "Murphy et al. 2015")

unique(effect_size$Study_ID) # Should be 17 studies.

# Merging severity with effect size data frame 
DNBR_model <- full_join(site_burn_severity, effect_size) %>% 
  dplyr::select(Study_ID, Site, response_var, Climate, Biome, fire_name, year, Effect_size_pair, Effect_size, mean_dnbr, burn_severity_category, burn_percentage, Time_Since_Fire) %>% 
  na.omit(burn_severity_category)


unique(DNBR_model$Study_ID) # 9 studies. It was 11 but we removed Murphy et al. 2015 and a duplicated Murphy et al. 2018 Should match the severity_clip data frame

DNBR_model <- DNBR_model %>% 
  mutate(burn_severity_category = case_when(burn_severity_category == "Unburned to Low" ~ "Low", 
                                           TRUE ~ burn_severity_category))
  
doc_es_dnbr <- DNBR_model %>% 
  filter(response_var == "DOC_Interp")

no3_es_dnbr <- DNBR_model %>% 
  filter(response_var == "NO3_Interp")

```

### CLIMATE MATCH PLOT with highest % being the category 
```{r severity plot with highest % as the category}
dnbr_percentage_effect <- DNBR_model %>% 
  group_by(response_var, burn_severity_category) %>% 
  summarise(mean_effect = mean(Effect_size, na.rm = TRUE),
            sd_effect = sd(Effect_size, na.rm = TRUE),
            n_effect = n(),
            Effect_size = mean(Effect_size, na.rm = TRUE)) %>% 
   mutate(se_effect = sd_effect / sqrt(n_effect),
         lower_ci_effect = mean_effect - qt(1 - (0.05 / 2), n_effect - 1) * se_effect,
         upper_ci_effect = mean_effect + qt(1 - (0.05 / 2), n_effect - 1) * se_effect) %>% 
  na.omit(burn_severity_category)

# Plot #
vn = expression(paste(""*N*O[3]^"-"))

give.n <- function(x){
  return(c(y = median(x)*1.5, label = length(x))) 
  # experiment with the multiplier to find the perfect position
}
# Refactor so we have low on the bottom and high on the top 
DNBR_model <- DNBR_model %>% 
  mutate(burn_severity_category = fct_relevel(burn_severity_category, "Low", "Moderate", "High"))

ggplot(DNBR_model, aes(x = Effect_size, y = burn_severity_category, color = response_var),
       position = position_dodge(width = -0.5)) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.4, size = 3) +
  geom_pointrange(aes(xmin = mean_effect - se_effect, xmax = mean_effect + se_effect,
                      color = response_var),
                  position = position_dodge(width = -0.5), size = 1.5, data = dnbr_percentage_effect) +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "red") +
  ylab("MTBS Severity") +
  xlab("Effect Size") +
  scale_color_manual(values = c("#00AFBB", "#E7B800"),
                     guide = guide_legend(title = ""),
                     labels = c('DOC', vn)) +
  scale_y_discrete(label = c("Low", "Moderate", "High")) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 30),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_text(size = 40),
        axis.title.y = element_text(size = 35),
        legend.text = element_text(size = 30),
        legend.key = element_blank(),
        legend.background = element_blank(),
        legend.position = c(0.2, 0.66))

ggsave("Effect_Size_DNBR_Severity.pdf",
       path = here("initial_plots", "14_Meta_calculate_burn_severity"),
       width = 10, height = 8, units = "in")

```

# Summary output 
```{r}
duplicate_comids <- fire_names %>%
  group_by(comid) %>%
  filter(n() > 1) %>%
  ungroup()

print(duplicate_comids)

# there are 8 duplicates
# Site_1 - angora fire
# Site_2 - angora fire
# US1 - fourmile_canyon fire - unburned
# US2 - fourmile_canyon fire - unburned
# Hobble_Creek_Lower - pole_creek - unburned
# Hobble_Creek_Upper - pole_creek - unburned

# DNBR model #
# How many observations per year 
ggplot(DNBR_model, aes(x = as.numeric(Time_Since_Fire))) +
  geom_histogram(fill = "darkred") +
  xlab("Time Since Fire") +
  ggtitle("DNBR observations per time since fire bin") +
  theme_bw()

# I think we are counting DS1 twice with both Murphy et al. 2015 and Murphy et al. 2018. 
# How many observations per watershed?
watershed_total <- DNBR_model_filter %>%
  group_by(Site, Time_Since_Fire, response_var) %>%
  summarise(Count = n()) %>%
  arrange(Site)

ggplot(watershed_total, aes(x = Site, y = Count)) +
  geom_point() +
  facet_wrap(~response_var, scales = "free") +
  theme_bw()

write_csv(watershed_total, here("Output_for_analysis", "14_Meta_calculate_burn_severity", "watershed_count_per_year.csv"))

# Omit the sites that don't have a burn severity category. This can be for a variety of reasons, it could have been because it was the reference (Unburned site)
na_omit_final <- final_burn_severity %>% 
  na.omit(burn_severity_category)

# Check how many burns are included
unique(final_burn_severity$fire_name) # 10 fires 
# red bench
# gaviota
# pole creek
# rampage_complex_double_mountain_2
# angora
# clovermist
# fourmile_canyon
# mosquito
# high_park
# wragg

# Check how many unique sites are included 
unique(na_omit_final$Site) # 29 sites 
unique(severity_clip$Site) # 20 sites 

# Summarize the number of observations for each burn level for each method
DNBR_summary <- na_omit_final %>%
  group_by(burn_severity_category) %>%
  summarise(Count = n()) %>%
  arrange(burn_severity_category)

MTBS_summary <- severity_clip %>%
  group_by(Severity_Category) %>%
  summarise(Count = n()) %>%
  arrange(Severity_Category)

```


# ================== Exploratory data analysis ======================================= 
```{r plot DNBR values as continuous against effect size}
# All years of data so there will be duplicate DNBR values for different effect sizes
ggplot(data = DNBR_model, aes(x = mean_dnbr, y = Effect_size, color = burn_severity_category)) +
  geom_point() +
  scale_color_manual(values = c("darkgreen", "#E7B800", "darkred"),
                     guide = guide_legend(title = "")) +
  xlab("Mean DNBR") +
  ylab("Effect Size") +
  ggtitle("All TSF years included") +
  facet_wrap(~response_var, scales = "free") +
  theme_bw() 

####  Filter only year 0 and 1 TSF ####
DNBR_model_filter_TSF <- DNBR_model %>% 
  filter(Time_Since_Fire == "0" | Time_Since_Fire == "1")

# Create a function to extract model info
model_info <- function(DNBR_model_filter_TSF) {
  model <- lm(Effect_size ~ mean_dnbr, data = DNBR_model_filter_TSF)
  intercept <- coef(model)[1]
  slope <- coef(model)[2]
  r_squared <- summary(model)$r.squared
  equation <- paste("y = ", round(intercept, 2), " + ", round(slope, 2), "*x", sep = "")
  r_squared_label <- paste("R² = ", round(r_squared, 2), sep = "")
  data.frame(equation = equation, r_squared_label = r_squared_label)
}

# Apply the function to each group
model_data <- DNBR_model_filter_TSF %>%
  group_by(response_var) %>%
  do(model_info(.))

ggplot(data = DNBR_model_filter_TSF, aes(x = mean_dnbr, y = Effect_size, color = burn_severity_category)) +
  geom_point() +
  scale_color_manual(values = c("darkgreen", "#E7B800", "darkred"),
                     guide = guide_legend(title = "")) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  geom_text(
    data = model_data, 
    aes(x = Inf, y = -Inf, label = paste(equation, "\n", r_squared_label)), 
    hjust = 1.5, vjust = -1, size = 3, color = "red", 
    inherit.aes = FALSE
  ) +
  xlab("Mean DNBR") +
  ylab("Effect Size") +
  ggtitle("Year 0 and 1 TSF years") +
  facet_wrap(~response_var, scales = "free") +
  theme_bw() 

####  Filter only one distinct mean_DNBR for year 0 or 1
DNBR_model_filter_dnbr <- DNBR_model %>% 
  group_by(response_var, Site) %>% 
  slice(1) %>%
  ungroup()
  
  # Create a function to extract model info
model_info <- function(DNBR_model_filter_dnbr) {
  model <- lm(Effect_size ~ mean_dnbr, data = DNBR_model_filter_dnbr)
  intercept <- coef(model)[1]
  slope <- coef(model)[2]
  r_squared <- summary(model)$r.squared
  equation <- paste("y = ", round(intercept, 2), " + ", round(slope, 2), "*x", sep = "")
  r_squared_label <- paste("R² = ", round(r_squared, 2), sep = "")
  data.frame(equation = equation, r_squared_label = r_squared_label)
}

# Apply the function to each group
model_data <- DNBR_model_filter_dnbr %>%
  group_by(response_var) %>%
  do(model_info(.))

ggplot(data = DNBR_model_filter_dnbr, aes(x = mean_dnbr, y = Effect_size, color = burn_severity_category)) +
  geom_point() +
  scale_color_manual(values = c("darkgreen", "#E7B800", "darkred"),
                     guide = guide_legend(title = "")) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  geom_text(
    data = model_data, 
    aes(x = Inf, y = -Inf, label = paste(equation, "\n", r_squared_label)), 
    hjust = 1.5, vjust = -1, size = 3, color = "red", 
    inherit.aes = FALSE
  ) +
  xlab("Mean DNBR") +
  ylab("Effect Size") +
  ggtitle("1st value") +
  facet_wrap(~response_var, scales = "free") +
  theme_bw() 

doc_filter <- DNBR_model_filter_dnbr %>% 
  filter(response_var == "DOC_Interp")


```


# ================== Checking sites individually that maybe don't make sense =========
Are Payson and Benjamin Slough being read as the same watershed?
# Pole Creek Fire 
```{r Benjamin Slough}
#section 1: load data layers ------ 
#section 1.1: load basin area 
site_shape <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/watershed_shapefile.shp")

# Benjamin Slough is site 20

# add location of the fire in the data frame
fire_names <- read_csv(here("inputs", "catchment_characteristics", "fire_watershed_lat_long_comids.csv")) %>%
  dplyr::select(site = Site, comid, fire_name)

site_shape_fire_combined <- full_join(site_shape, fire_names)

dnbr <- raster(here("gis_data", "Fire_Perimeters", "pole_creek", "mtbs", "2018", "ut3980611166020180906", "pole_creek_dnbr.tif"))

fire_shape <- read_sf(here("gis_data", "Fire_Perimeters", "pole_creek", "mtbs", "2018", "ut3980611166020180906", "pole_creek_burn_bndy.shp"))


# Clip data to the watershed
dnbr <- clean_raster(dnbr, fire_shape, type = "numeric", return="raster")
plot(dnbr) #use to make sure it's doing what you expect

#section 2.2: clip the DNBR data to the watershed boundry # This doesnt work for me, I don't know if this is what is correct
# Benjamin Slough is site 20

basin_dnbr <- clean_raster(dnbr, site_shape[20, ],  type = "numeric", return="raster")
plot(basin_dnbr) #use to make sure it's doing what you expect
plot(site_shape$geometry[20, ])

#section 3.1: make sure basin and fire layer are the same projection
if(compareCRS(dnbr, site_shape[20, ]) == F){
      basin_pj <- st_transform(site_shape[20, ], crs(dnbr))}else{
        basin_pj <- site_shape[20, ]
      }

#extract data
mean_dnbr <- exactextractr::exact_extract(dnbr,basin_pj, "mean", 
                                           progress=F) 
# Benjamin Slough mean DNBR 102.01708984375

```

```{r Payson}
#section 1: load data layers ------ 

# Payson is site 23

# read in fire 
dnbr <- raster(here("gis_data", "Fire_Perimeters", "pole_creek", "mtbs", "2018", "ut3980611166020180906", "pole_creek_dnbr.tif"))

fire_shape <- read_sf(here("gis_data", "Fire_Perimeters", "pole_creek", "mtbs", "2018", "ut3980611166020180906", "pole_creek_burn_bndy.shp"))


# Clip data to the watershed
dnbr <- clean_raster(dnbr, fire_shape, type = "numeric", return="raster")
plot(dnbr) #use to make sure it's doing what you expect
plot(site_shape$geometry[23, ])

#section 2.2: clip the DNBR data to the watershed boundry # This doesnt work for me, I don't know if this is what is correct
# Benjamin Slough is site 20

basin_dnbr <- clean_raster(dnbr, site_shape[23, ],  type = "numeric", return="raster")
plot(basin_dnbr) #use to make sure it's doing what you expect

#section 3.1: make sure basin and fire layer are the same projection
if(compareCRS(dnbr, site_shape[23, ]) == F){
      basin_pj <- st_transform(site_shape[23, ], crs(dnbr))}else{
        basin_pj <- site_shape[23, ]
      }

#extract data
mean_dnbr <- exactextractr::exact_extract(dnbr,basin_pj, "mean", 
                                           progress=F) 
# Payson mean DNBR 102.01708984375

```

```{Payson and Benjamin shp plotted together}
# Read in watershed shape file
watershed_shape <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/watershed_shapefile.shp") %>%
    filter(site %in% c("Payson", "Benjamin_Slough", "Spanish_Fork_Lower", "Spanish_Fork_Upper"))

# Read in pole creek fire 
fire_shape <- read_sf(here("gis_data", "Fire_Perimeters", "pole_creek", "mtbs", "2018", "ut3980611166020180906", "pole_creek_burn_bndy.shp"))

# Plot fire shape file 
ggplot(data = fire_shape) +
  geom_sf(aes(fill = "red")) +
  theme_minimal()

# plot on top of each other 
ggplot() +
  geom_sf(data = watershed_shape, fill = "#56B4E9", alpha = 0.2, color = "black") +
  geom_sf(data = fire_shape, fill = "red", alpha = 0.2, color = "black") +
  theme_minimal()

# plot only Benjamin Slough 
ggplot() +
  geom_sf(data = watershed_shape[1, ], fill = "#56B4E9", alpha = 0.2, color = "black") +
  geom_sf(data = fire_shape, fill = "red", alpha = 0.2, color = "black") +
  theme_minimal()

# plot only Spanish Fork Lower
ggplot() +
  geom_sf(data = watershed_shape[2, ], fill = "#56B4E9", alpha = 0.2, color = "black") +
  geom_sf(data = fire_shape, fill = "red", alpha = 0.2, color = "black") +
  theme_minimal()

# plot only Spanish Fork Upper
ggplot() +
  geom_sf(data = watershed_shape[3, ], fill = "#56B4E9", alpha = 0.2, color = "black") +
  geom_sf(data = fire_shape, fill = "red", alpha = 0.2, color = "black") +
  theme_minimal()

# plot only Payson 
ggplot() +
  geom_sf(data = watershed_shape[4, ], fill = "#56B4E9", alpha = 0.2, color = "black") +
  geom_sf(data = fire_shape, fill = "red", alpha = 0.2, color = "black") +
  theme_minimal()

# Payson is a subsection of Benjamin slough and the only part that is burned is the Payson portion so that is why the DNBR values are the same. 


```















# ==================================== Script Graveyard =================================
# Read in site shape files #
```{r}
# # Can just read in the shape file of all the watersheds
# site_shape <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/Output_for_analysis/06_Meta_geospatial_extraction_with_comids/watershed_shapefile.shp")
# 
# # add location of the fire in the data frame 
# fire_names <- read_csv(here("inputs", "catchment_characteristics", "fire_watershed_lat_long_comids.csv")) %>% 
#   dplyr::select(site = Site, comid, fire_name)
#   
# 
# 
# site_shape_fire_combined <- full_join(site_shape, fire_names)
# 
# ```
# 
# # Read in fire files
# ```{r}
# #load in the dnbr and shapefile
# dnbr <- raster(here("gis_data", "Fire_Perimeters", "gaviota", "mtbs", "2004", "ca3448712019620040605", "gaviota_dnbr.tif"))
# 
# fire_shape <- read_sf(here("gis_data", "Fire_Perimeters", "gaviota", "mtbs", "2004", "ca3448712019620040605", "gaviota_burn_bndy.shp"))
# 
# ```
# 
# # Clip data to the watershed
# ```{r}
# #section 2.1: clip the DNBR data to the fire boundry 
# dnbr <- clean_raster(dnbr, fire_shape, type = "numeric", return="raster")
# plot(dnbr) #use to make sure it's doing what you expect
#     
# #section 2.2: clip the DNBR data to the watershed boundry # This doesnt work for me, I don't know if this is what is correct
# basin_dnbr <- clean_raster(dnbr, site_shape[36, ],  type = "numeric", return="raster")
# plot(basin_dnbr) #use to make sure it's doing what you expect
# 
# ```
# 
# # Section 3: Get the average DNBR
# ```{r}
# # NOTE HERE: this deviates from my method where unburned areas in the basin were give 0's. The method done here will get the average severity of just the area in the basin the burned 
#     
# #section 3.1: make sure basin and fire layer are the same projection
# if(compareCRS(dnbr, site_shape[36, ]) == F){
#       basin_pj <- st_transform(site_shape[36, ], crs(dnbr))}else{
#         basin_pj <- site_shape[36, ]
#         }
#     
# #extract data
# mean_dnbr <- exactextractr::exact_extract(dnbr,basin_pj, "mean", 
#                                            progress=F)
# 
# # Read in thresholds data frame that we created that have the ranges for each fire
# thresholds <- read_csv(here("Output_for_analysis", "13_Meta_calculate_thresholds_per_fire", "Fire_thresholds.csv"))
# 
# 
# burn_severity <- tibble(
#   site = character(),
#   mean_dnbr = numeric(),
#   Burn_Severity = character()
# )
# 
# 
# # Gaviota is listed as Unburned
# # Maybe go one step further and check the meta data to extract or calculate the thresholds for each fire. 
# 
# ```
# # load in sites and their comid's
# ```{r load in meta_lat_longs}
# site_comids <- read_csv(here("inputs", "catchment_characteristics", "meta_lat_long_comids.csv"))
# 
# # Function to parse the geometry string
# parse_geometry <- function(geom_str) {
#   coords <- as.numeric(str_extract_all(geom_str, "-?\\d+\\.\\d+")[[1]])
#   st_point(coords)
# }
# 
# # Use mutate to parse the geometry and convert to sf object
# site_comids_sf <- site_comids %>%
#   mutate(
#     geometry = purrr::map(geometry, parse_geometry),
#     geometry = sf::st_sfc(geometry, crs = 4326)
#   ) %>%
#   st_as_sf()
# 
# ```
# 
# # Plot gaviota fire test 
# ```{r}
# # Read the shapefile
# burn_boundary <- st_read("~/GitHub/rc_sfa-rc-3-wenas-meta/gis_data/Fire_Perimeters/gaviota/mtbs/2004/ca3448712019620040605/ca3448712019620040605_20040425_20050412_burn_bndy.shp")
# 
# # Plot using ggplot2
# ggplot() +
#   geom_sf(data = burn_boundary) +
#   ggtitle("Burn Boundary") +
#   theme_minimal()

#section 3.2: classify based on mean dnbr
  ## Based on Lutes, D. C., Keane, R. E., Caratti, J. F., Key, C. H., Benson, N. C., Sutherland, S., & Gangi, L. J. (2006). FIREMON: Fire effects monitoring and inventory system. Gen. Tech. Rep. RMRS-GTR-164. Fort Collins, CO: U.S. Department of Agriculture, Forest Service, Rocky Mountain Research Station. 1 CD., 164. https://doi.org/10.2737/RMRS-GTR-164

#thresholds <- data.frame(severity=c("Regrowth", "Unburned", "Low","Moderate-low","Moderate-high",
                               #         "High"),
                             #low_dnbr =c(-500, -100, 100, 270, 440, 600),
                             #high_dnbr=c(-101, 99,269,439,659,1300))

# sev_level <- thresholds$severity[mean_dnbr >= thresholds$low_dnbr & mean_dnbr < thresholds$high_dnbr] 
    
  
# cat("Mean DNBR is ", round(mean_dnbr, 0),
#         ", which is classified as: ", sev_level, sep="")


```




